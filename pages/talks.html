<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talks - LE TRUNG LINH</title>
    <meta name="description" content="Conference talks, invited presentations, and seminars by LE TRUNG LINH on AI research, safety, and interpretability.">
    <meta name="keywords" content="AI talks, conference presentations, seminars, invited talks, research presentations">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Talks - LE TRUNG LINH">
    <meta property="og:description" content="Conference talks and presentations on AI research, safety, and interpretability.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://YOURUSERNAME.github.io/pages/talks.html">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://YOURUSERNAME.github.io/pages/talks.html">
    
    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸŽ¤</text></svg>">
    
    <!-- Styles -->
    <link rel="stylesheet" href="../css/styles.css">
</head>
<body>
    <!-- Skip to main content -->
    <a href="#main-content" class="skip-link">Skip to main content</a>
    
    <!-- Header -->
    <header class="header">
        <div class="container">
            <nav class="nav" role="navigation" aria-label="Main navigation">
                <div class="nav-brand">
                    <a href="../" class="nav-brand-link" aria-label="Home">LE TRUNG LINH</a>
                </div>
                <ul class="nav-menu" role="menubar">
                    <li role="none"><a href="../" class="nav-link" role="menuitem">Home</a></li>
                    <li role="none"><a href="publications.html" class="nav-link" role="menuitem">Publications</a></li>
                    <li role="none"><a href="talks.html" class="nav-link" role="menuitem" aria-current="page">Talks</a></li>
                    <li role="none"><a href="teaching.html" class="nav-link" role="menuitem">Teaching</a></li>
                    <li role="none"><a href="service.html" class="nav-link" role="menuitem">Service</a></li>
                    <li role="none"><a href="cv.html" class="nav-link" role="menuitem">CV</a></li>
                </ul>
                <button class="theme-toggle" aria-label="Toggle dark mode" title="Toggle dark mode">
                    <span class="theme-toggle-icon">ðŸŒ™</span>
                </button>
            </nav>
        </div>
    </header>

    <!-- Main Content -->
    <main id="main-content" class="main">
        <section class="section">
            <div class="container">
                <h1 class="section-title">Talks & Presentations</h1>
                
                <div class="simple-list">
                    <ul style="list-style: none;">
                        <li>
                            <div class="list-item-title">Robust Alignment of Large Language Models through Constitutional AI</div>
                            <div class="list-item-meta">ICLR 2025 â€¢ March 2025 â€¢ Vienna, Austria</div>
                            <div class="list-item-description">
                                Oral presentation of our accepted paper on constitutional AI training methods for large language models. 
                                Discussed novel approaches to aligning AI systems with human values while maintaining performance.
                                <br><br>
                                <a href="../files/iclr2025_slides.pdf" class="btn btn-secondary">Slides</a>
                                <a href="https://youtube.com/watch?v=example1" class="btn btn-secondary">Video</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">AI Safety in the Era of Large Language Models</div>
                            <div class="list-item-meta">AI Safety Workshop, ICML 2025 â€¢ July 2025 â€¢ Honolulu, Hawaii</div>
                            <div class="list-item-description">
                                Invited keynote presentation discussing the current challenges and future directions in AI safety research, 
                                particularly focusing on large language models and their alignment with human values.
                                <br><br>
                                <a href="../files/icml2025_keynote_slides.pdf" class="btn btn-secondary">Slides</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">Interpretable Decision-Making in Multi-Agent Systems</div>
                            <div class="list-item-meta">UAI 2025 â€¢ August 2025 â€¢ Tel Aviv, Israel</div>
                            <div class="list-item-description">
                                Conference presentation on our framework for interpretable multi-agent reinforcement learning. 
                                Demonstrated how to provide human-understandable explanations for agent actions in complex environments.
                                <br><br>
                                <a href="../files/uai2025_slides.pdf" class="btn btn-secondary">Slides</a>
                                <a href="../files/uai2025_poster.pdf" class="btn btn-secondary">Poster</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">The Future of Constitutional AI</div>
                            <div class="list-item-meta">AI Alignment Conference 2025 â€¢ February 2025 â€¢ San Francisco, CA</div>
                            <div class="list-item-description">
                                Invited talk discussing the future directions of constitutional AI research and its implications for 
                                building safe and aligned AI systems. Covered scaling laws and practical implementation challenges.
                                <br><br>
                                <a href="../files/alignment_conf_2025_slides.pdf" class="btn btn-secondary">Slides</a>
                                <a href="https://youtube.com/watch?v=example2" class="btn btn-secondary">Video</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">Robust Policy Learning under Distribution Shift</div>
                            <div class="list-item-meta">NeurIPS 2024 â€¢ December 2024 â€¢ Vancouver, Canada</div>
                            <div class="list-item-description">
                                Poster presentation of our work on robust reinforcement learning methods that maintain performance 
                                across diverse environmental conditions and distribution shifts.
                                <br><br>
                                <a href="../files/neurips2024_poster.pdf" class="btn btn-secondary">Poster</a>
                                <a href="../files/neurips2024_slides.pdf" class="btn btn-secondary">Slides</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">Privacy-Preserving AI Alignment through Federated Learning</div>
                            <div class="list-item-meta">ICML 2024 â€¢ July 2024 â€¢ Vienna, Austria</div>
                            <div class="list-item-description">
                                Conference presentation on our federated learning approach to AI alignment, demonstrating how 
                                to align AI systems with diverse human values while preserving privacy.
                                <br><br>
                                <a href="../files/icml2024_slides.pdf" class="btn btn-secondary">Slides</a>
                                <a href="https://youtube.com/watch?v=example3" class="btn btn-secondary">Video</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">Graduate Seminar: Introduction to AI Safety</div>
                            <div class="list-item-meta">Your Lab / Institution â€¢ April 2024 â€¢ City, Country</div>
                            <div class="list-item-description">
                                Graduate-level seminar introducing fundamental concepts in AI safety research, covering alignment problems, 
                                robustness challenges, and current research directions in building safe AI systems.
                                <br><br>
                                <a href="../files/grad_seminar_2024_slides.pdf" class="btn btn-secondary">Slides</a>
                            </div>
                        </li>
                        
                        <li>
                            <div class="list-item-title">Emergent Communication in Multi-Agent Reinforcement Learning</div>
                            <div class="list-item-meta">ICLR 2024 â€¢ May 2024 â€¢ Vienna, Austria</div>
                            <div class="list-item-description">
                                Conference presentation on emergent communication protocols in multi-agent systems, exploring 
                                how agents develop sophisticated communication strategies for coordination and cooperation.
                                <br><br>
                                <a href="../files/iclr2024_slides.pdf" class="btn btn-secondary">Slides</a>
                                <a href="../files/iclr2024_poster.pdf" class="btn btn-secondary">Poster</a>
                                <a href="https://youtube.com/watch?v=example4" class="btn btn-secondary">Video</a>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 LE TRUNG LINH. All rights reserved.</p>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../js/main.js"></script>
</body>
</html>
